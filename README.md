 Explainable AI with Grad-CAM and its Variants

This project explores **visual explanation techniques** for Convolutional Neural Networks (CNNs) using **Grad-CAM**, **Grad-CAM++**, **Score-CAM**, and **Ablation-CAM**. The goal is to visualize and interpret deep learning models by highlighting the regions in an image that influence the model's decisions.

üìå Features

- Visual explanations for CNN-based image classifiers
- Comparison of four XAI techniques:
  - Grad-CAM
  - Grad-CAM++
  - Score-CAM
  - Ablation-CAM
- Interactive Streamlit interface for uploading images and viewing explanations
- Modular and extensible codebase

---

 üß† Why Explainability?

Deep learning models often act as black boxes. Explainability methods like Grad-CAM help:
- Understand **what** the model is focusing on
- Build **trust** in model predictions
- Debug and **improve** model performance

---

üõ†Ô∏è Setup Instructions

1. Clone the repository**:
```bash
git clone https://github.com/yourusername/grad-cam-xai.git
cd grad-cam-xai
